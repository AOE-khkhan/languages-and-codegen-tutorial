{
 "metadata": {
  "name": "",
  "signature": "sha256:97f6179238a76d6edfc602e8cb4b4079b8fa538ee83471820af812fdd1129ecb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#keep\n",
      "from __future__ import division\n",
      "import numpy as np\n",
      "import pyopencl as cl\n",
      "import pyopencl.array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python2.7/pkgutil.py:186: ImportWarning: Not importing directory '/usr/lib/python2.7/dist-packages/enthought': missing __init__.py\n",
        "  file, filename, etc = imp.find_module(subname, path)\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load the PyOpenCL IPython extension: (very new!)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#keep\n",
      "%load_ext pyopencl.ipython"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create an OpenCL context and a command queue:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#keep\n",
      "ctx = cl.create_some_context()\n",
      "queue = cl.CommandQueue(ctx)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "-----\n",
      "\n",
      "Define an OpenCL kernel using the `%%cl_kernel` magic:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cl_kernel\n",
      "// #keep\n",
      "\n",
      "__kernel void sum_vector(__global const float *a,\n",
      "__global const float *b, __global float *c)\n",
      "{\n",
      "  int gid = get_global_id(0);\n",
      "  c[gid] = a[gid] + b[gid];\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This looks for `cl_ctx` or `ctx` in the user namespace to find a PyOpenCL context.\n",
      "\n",
      "Kernel names are automatically injected into the user namespace, so we can just use `sum_vector` from Python below.\n",
      "\n",
      "Now create some data to work on:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#keep\n",
      "n = 10000\n",
      "\n",
      "a = cl.array.empty(queue, n, dtype=np.float32)\n",
      "a.fill(15)\n",
      "\n",
      "b_host = np.random.randn(n).astype(np.float32)\n",
      "b = cl.array.to_device(queue, b_host)\n",
      "\n",
      "c = cl.array.empty_like(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run the kernel:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#keep\n",
      "sum_vector(queue, (n,), None, a.data, b.data, c.data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "<pyopencl._cl.Event at 0x3c80b40>"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check the result using `numpy` operations:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#keep\n",
      "assert (c.get() == b_host + 15).all()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    }
   ],
   "metadata": {}
  }
 ]
}